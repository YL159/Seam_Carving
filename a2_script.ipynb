{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19aff683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as tf\n",
    "import kornia\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742b2098",
   "metadata": {},
   "source": [
    "## 1 Canny edge detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172f48fe",
   "metadata": {},
   "source": [
    "### Q1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5da3a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_derivative_filtering(image:torch.Tensor, length:int=3, sigma:float=1.) -> tuple:\n",
    "    # flip the x filter. conv2d function is using cross-correlation\n",
    "    x0 = torch.linspace(sigma, -sigma, length)\n",
    "    x = x0.expand(length, -1)\n",
    "    y = x0.reshape(length,1).expand(-1, length)\n",
    "    \n",
    "    # x direction Gaussian filter [B=1,C=1,H=length,W=length]\n",
    "    gexp = torch.exp(-(torch.square(x) + torch.square(y)) / (2*sigma**2))\n",
    "    gauss = gexp / (2*torch.pi*sigma**2)\n",
    "    dx = (-(x / sigma**2) * gauss).view(1,1,length,length)\n",
    "    dy = (-(y / sigma**2) * gauss).view(1,1,length,length)\n",
    "\n",
    "    \n",
    "    # replicate edge padding image with half filter length\n",
    "    p = length//2\n",
    "    pad_img = tf.pad(image, [p,p,p,p], mode='replicate')\n",
    "    \n",
    "    Ix = tf.conv2d(pad_img, dx)\n",
    "    Iy = tf.conv2d(pad_img, dy)\n",
    "    \n",
    "    return Ix, Iy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b67034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_row2(img1:torch.Tensor, img2:torch.Tensor, title1:str, title2:str, cm:str=None) -> None:\n",
    "    # helper func to show 2 image tensors in 1 row\n",
    "    _, (g0, g1) = plt.subplots(1,2, figsize=(12,6))\n",
    "    g0.imshow(img1.squeeze(), cmap=cm)\n",
    "    g0.set_title(title1)\n",
    "    g1.imshow(img2.squeeze(), cmap=cm)\n",
    "    g1.set_title(title2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b64fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude_rl(magnitude:torch.Tensor, direction:torch.Tensor) -> tuple:\n",
    "    # helper to return the \"left\" and \"right\" comparison targets of magnitude, based on direction INT value\n",
    "    # MUCH faster than my original magnitude_edge(), see below\n",
    "    r0_up = torch.roll(magnitude, -1, dims=2)\n",
    "    r0_up[..., -1, :] = r0_up[..., -2, :]\n",
    "\n",
    "    r1_lu = torch.roll(magnitude, (-1, -1), dims=(2,3))\n",
    "    r1_lu[..., -1, :] = r1_lu[..., -2, :]\n",
    "    r1_lu[..., -1] = r1_lu[..., -2]\n",
    "\n",
    "    r2_l = torch.roll(magnitude, -1, dims=3)\n",
    "    r2_l[..., -1] = r2_l[..., -2]\n",
    "\n",
    "    r3_ld = torch.roll(magnitude, (1, -1), dims=(2,3))\n",
    "    r3_ld[..., 0, :] = r3_ld[..., 1, :]\n",
    "    r3_ld[..., -1] = r3_ld[..., -2]\n",
    "\n",
    "    r0 = torch.where(direction==0, r0_up, 0)\n",
    "    r1 = torch.where(direction==1, r1_lu, 0)\n",
    "    r2 = torch.where(direction==2, r2_l, 0)\n",
    "    r3 = torch.where(direction==3, r3_ld, 0)\n",
    "\n",
    "    l0_down = torch.roll(magnitude, 1, dims=2)\n",
    "    l0_down[..., 0, :] = l0_down[..., 1, :]\n",
    "\n",
    "    l1_rd = torch.roll(magnitude, (1, 1), dims=(2,3))\n",
    "    l1_rd[..., 0, :] = l1_rd[..., 1, :]\n",
    "    l1_rd[..., 0] = l1_rd[..., 1]\n",
    "\n",
    "    l2_r = torch.roll(magnitude, 1, dims=3)\n",
    "    l2_r[..., 0] = l2_r[..., 1]\n",
    "\n",
    "    l3_ru = torch.roll(magnitude, (-1, 1), dims=(2,3))\n",
    "    l3_ru[..., -1, :] = l3_ru[..., -2, :]\n",
    "    l3_ru[..., 0] = l3_ru[..., 1]\n",
    "\n",
    "    l0 = torch.where(direction==0, l0_down, 0)\n",
    "    l1 = torch.where(direction==1, l1_rd, 0)\n",
    "    l2 = torch.where(direction==2, l2_r, 0)\n",
    "    l3 = torch.where(direction==3, l3_ru, 0)\n",
    "\n",
    "    return (r0 + r1 + r2 + r3, l0 + l1 + l2 + l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35e8092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude_edge(magnitude:torch.Tensor, dire_pent:torch.Tensor) -> torch.Tensor:\n",
    "    # alternative double loop way to get magnitude edges\n",
    "    # slow compared to magnitude_rl()\n",
    "    choices = {\n",
    "        0: (lambda i, j: ((i+1, j  ), (i-1, j  ))),\n",
    "        1: (lambda i, j: ((i+1, j+1), (i-1, j-1))),\n",
    "        2: (lambda i, j: ((i  , j+1), (i  , j-1))),\n",
    "        3: (lambda i, j: ((i-1, j+1), (i+1, j-1))),\n",
    "    }\n",
    "    pad_mag = tf.pad(magnitude, [1,1,1,1], mode='replicate').squeeze()\n",
    "    \n",
    "    # perform non-maximum supression on each pixel\n",
    "    edge = torch.zeros_like(magnitude.squeeze())\n",
    "    h, w = image.shape[-2:]\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            pr, pl = choices[dire_pent[i, j].item()](i+1, j+1)\n",
    "            center = pad_mag[i+1, j+1]\n",
    "            if center > pad_mag[pr] and center >= pad_mag[pl]:\n",
    "                edge[i, j] = center\n",
    "    return edge.view(1,1,h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "087896cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyCanny(image:torch.Tensor, sigma:float) -> torch.Tensor:\n",
    "    # 1. Filter image with x, y derivatives of Gaussian filter\n",
    "    Ix, Iy = gauss_derivative_filtering(image, 3, sigma)\n",
    "    \n",
    "    # example x, y gradient with kornia sobel filter, and compare with native gradient filter\n",
    "    example = kornia.filters.spatial_gradient(image, mode='sobel')\n",
    "    eg_x, eg_y = torch.split(example, 1, dim=2)\n",
    "    \n",
    "#     # show temporal results\n",
    "#     imshow_row2(Ix, Iy, \"x gradient of image\", \"y gradient of image\", \"gray\")\n",
    "#     imshow_row2(eg_x, eg_y, \"kornia x gradient of image\", \"kornia y gradient of image\", \"gray\")\n",
    "    \n",
    "    # 2. Find magnitude & direction of image gradient\n",
    "    magnitude = torch.sqrt(torch.square(Ix) + torch.square(Iy))\n",
    "    direction = torch.atan(Iy / Ix).nan_to_num_()\n",
    "    imshow_row2(magnitude.squeeze(), direction.squeeze(), \"magnitude\", \"direction\", \"gray\")\n",
    "    \n",
    "    # 3. Perform non-maximum suppression\n",
    "    # prepare direction matrix into positive and multitude of pi/4 for neighbor choices\n",
    "    dire_pent = torch.div(direction.squeeze() + torch.pi*5/8, torch.pi/4, rounding_mode='floor').squeeze().int()\n",
    "    # truncate the same comparisons of top-down and down-top\n",
    "    dire_pent %= 4\n",
    "    \n",
    "    right, left = magnitude_rl(magnitude, dire_pent)\n",
    "    NMS_bool = torch.logical_and(magnitude > right, magnitude >= left)\n",
    "    NMS = torch.where(NMS_bool, magnitude, 0)\n",
    "#     plt.imshow(NMS.squeeze(), cmap='gray')\n",
    "    # return Non Maximum Suppression edges with dimension 1*1*H*W\n",
    "    return NMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8963a303",
   "metadata": {},
   "source": [
    "### Q1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47bd46f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_8(pad:torch.Tensor) -> tuple:\n",
    "    # return 8x frames clock-wise with 1*1*H-2*W-2 of given pad\n",
    "    p0 = pad[..., :-2, 1:-1]\n",
    "    p1 = pad[..., :-2, 2:]\n",
    "    p2 = pad[..., 1:-1, 2:]\n",
    "    p3 = pad[..., 2:, 2:]\n",
    "    p4 = pad[..., 2:, 1:-1]\n",
    "    p5 = pad[..., 2:, :-2]\n",
    "    p6 = pad[..., 1:-1, :-2]\n",
    "    p7 = pad[..., :-2, :-2]\n",
    "    return (p0, p1, p2, p3, p4, p5, p6, p7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b05e2230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyCannyFull(image:torch.Tensor, sigma:float, high_max_ratio:float) -> torch.Tensor:\n",
    "    edge = MyCanny(image, sigma)\n",
    "#     plt.imshow(edge.squeeze(), cmap='gray')\n",
    "    \n",
    "    # For this function, instead of giving a high threshold\n",
    "    # high threshold is (0 < high_max_ratio <= 1) of max intensity\n",
    "    if high_max_ratio <= 0.:\n",
    "        print(f'high_max_ratio {high_max_ratio} should be (0, 1]')\n",
    "        return image\n",
    "    \n",
    "    # 4. Hysteresis thresholding\n",
    "    maximum = torch.max(edge)\n",
    "    high = maximum * high_max_ratio\n",
    "    hyst = torch.where(edge >= high, 1., 0.)\n",
    "    pad_hyst = tf.pad(hyst, [1,1,1,1], mode='constant', value=0.)\n",
    "    p0, p1, p2, p3, p4, p5, p6, p7 = window_8(pad_hyst) \n",
    "    \n",
    "    new_count = torch.sum(hyst == 1.)\n",
    "    count = 0\n",
    "    diff = new_count\n",
    "    while diff:\n",
    "        print(diff)\n",
    "        count = new_count\n",
    "        b0 = torch.logical_and(p0 == 1, edge > 0)\n",
    "        b1 = torch.logical_and(p1 == 1, edge > 0)\n",
    "        b2 = torch.logical_and(p2 == 1, edge > 0)\n",
    "        b3 = torch.logical_and(p3 == 1, edge > 0)\n",
    "        b4 = torch.logical_and(p4 == 1, edge > 0)\n",
    "        b5 = torch.logical_and(p5 == 1, edge > 0)\n",
    "        b6 = torch.logical_and(p6 == 1, edge > 0)\n",
    "        b7 = torch.logical_and(p7 == 1, edge > 0)\n",
    "        b01 = torch.logical_or(b0, b1)\n",
    "        b23 = torch.logical_or(b2, b3)\n",
    "        b45 = torch.logical_or(b4, b5)\n",
    "        b67 = torch.logical_or(b6, b7)\n",
    "        b03 = torch.logical_or(b01, b23)\n",
    "        b47 = torch.logical_or(b45, b67)\n",
    "        candidate = torch.logical_or(b03, b47)\n",
    "        hyst = torch.where(candidate, 1., hyst)\n",
    "        new_count = torch.sum(hyst == 1.)\n",
    "        diff =  new_count - count\n",
    "    \n",
    "    return hyst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5fe82f",
   "metadata": {},
   "source": [
    "## 2 Seam Carving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "106d3483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MySeamCarving(image_origin:torch.Tensor, target_h:int, target_w:int) -> np.ndarray:\n",
    "    h, w = image_origin.shape[-2:]\n",
    "    print(h, target_h, w, target_w)\n",
    "    if h < target_h or w < target_h:\n",
    "        print('Target image dimension is not supported or needed to be processed by this function')\n",
    "        return image_origin\n",
    "    \n",
    "    image = image_origin.detach().clone()\n",
    "    transposed = target_h < h\n",
    "    while h > target_h or w > target_w:\n",
    "        if target_w == w and target_h < h:\n",
    "            image = torch.transpose(image, dim0=2, dim1=3)\n",
    "            h, w = w, h\n",
    "            target_h, target_w = target_w, target_h\n",
    "        \n",
    "        # 1. Get spacial gradient for each channel of given image, get Ix, Iy of 1*C*H*W\n",
    "        grad = kornia.filters.spatial_gradient(image, mode=\"sobel\")\n",
    "        Ix, Iy = torch.split(grad, 1, dim=2)\n",
    "\n",
    "        # 2. Compute Energy or sum of magnitude of gradient on all channels, get Energy of H*W\n",
    "        magnitude = torch.sqrt(torch.square(Ix) + torch.square(Iy))\n",
    "        energy = torch.sum(magnitude, dim=1).squeeze()\n",
    "\n",
    "        # 3. DP score board and find lowest energy vertical seam\n",
    "        score = torch.zeros_like(energy)\n",
    "        score[0, :] = energy[0, :]\n",
    "        for i in range(1, h):\n",
    "            # DP on score board\n",
    "            last = score[i-1, :]\n",
    "            left = torch.roll(last, 1)\n",
    "            left[0] = last[0]\n",
    "            right = torch.roll(last, -1)\n",
    "            right[-1] = last[-1]\n",
    "            score[i, :] = energy[i, :] + torch.minimum(torch.minimum(last, left), right)\n",
    "        seam = torch.zeros(h, dtype=torch.int64)\n",
    "        seam[-1] = torch.argmin(score[-1, :])\n",
    "        \n",
    "        # 4. Backtrack for the vertical seam and remove it\n",
    "        for i in range(h-2, -1, -1):\n",
    "            # backtrack for seam indices\n",
    "            m = seam[i+1]\n",
    "            l, r = max(m-1, 0), min(m+1, w-1)\n",
    "            three = [score[i, l], score[i, m], score[i, r]]\n",
    "            seam[i] = m + three.index(min(three)) - 1\n",
    "            seam[i] = min(max(seam[i], 0), w-1)\n",
    "        \n",
    "        # 5. Carve image on all channels at seam\n",
    "        image = CarvingHelper(image, seam)\n",
    "        h, w = image.shape[-2:]\n",
    "    \n",
    "    if transposed:\n",
    "        print(\"transposed!\")\n",
    "        image = torch.transpose(image, dim0=2, dim1=3)\n",
    "    return np.transpose(image.squeeze().numpy(), (1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9437a343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CarvingHelper(image:torch.Tensor, seam:torch.Tensor) -> torch.Tensor:\n",
    "    # Remove a vertical seam from image at position seam of each line\n",
    "    h, w = image.shape[-2:]\n",
    "    for i in range(h):\n",
    "        image[..., i, :] = torch.cat((image[..., i, :seam[i]], torch.roll(image[..., i, seam[i]:], -1, dims=2)), 2)\n",
    "    return image[..., :w-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
